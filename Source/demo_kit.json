{
    "jsonversion": "1.0.0",
    "demokitVersion": "8.0.0-beta09",
    "openvinoVersion": "2022.1.0.643",
    "openvinoPath": "/opt/intel/openvino_2022",
    "pythonExcute": "/usr/bin/python3",
    "modelPath": "$HOME",
    "convertPath": "modelPath",
    "datasetPath": "modelPath",
    "OMZ":
    {
        "source": "https://github.com/openvinotoolkit/open_model_zoo/archive/refs/tags/",
        "git": "https://github.com/openvinotoolkit/open_model_zoo.git",
        "tag": "2022.1.0",
        "asset": ".tar.gz",
        "path": "$HOME"
    },
    "sample":
    {
        "source": "/opt/intel/openvino_2022/samples/cpp",
        "path": "$HOME"
    },
    "benchmark":
    {
        "reportPath": "default",
        "reportName": "OpenVINO_Benchmark_Report",
        "path": "",
        "report": true,
        "modelBan": [],
        "skip": 12
    },
    "demos":
    [
        {
            "name": "Classification Benchmark C++ Demo",
            "description": "The demo visualizes OpenVINO performance on inference of neural networks for image classification.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "classification_benchmark_demo",
            "modelList": "/demos/classification_benchmark_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Image Classification model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained model.",
                            "default": "squeezenet1.1",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "alexnet",
                                "caffenet",
                                "convnext-tiny",
                                "densenet-121",
                                "densenet-121-tf",
                                "dla-34",
                                "efficientnet-b0",
                                "efficientnet-b0-pytorch",
                                "googlenet-v1",
                                "googlenet-v1-tf",
                                "googlenet-v2",
                                "googlenet-v2-tf",
                                "googlenet-v3",
                                "googlenet-v3-pytorch",
                                "googlenet-v4-tf",
                                "hbonet-0.25",
                                "hbonet-1.0",
                                "inception-resnet-v2-tf",
                                "levit-128s",
                                "mixnet-l",
                                "mobilenet-v1-0.25-128",
                                "mobilenet-v1-1.0-224",
                                "mobilenet-v1-1.0-224-tf",
                                "mobilenet-v2",
                                "mobilenet-v2-1.0-224",
                                "mobilenet-v2-1.4-224",
                                "mobilenet-v2-pytorch",
                                "mobilenet-v3-large-1.0-224-tf",
                                "mobilenet-v3-small-1.0-224-tf",
                                "mobilenet-v3-large-1.0-224-paddle",
                                "mobilenet-v3-small-1.0-224-paddle",
                                "nfnet-f0",
                                "octave-resnet-26-0.25",
                                "regnetx-3.2gf",
                                "repvgg-a0",
                                "repvgg-b1",
                                "repvgg-b3",
                                "resnest-50-pytorch",
                                "resnet-18-pytorch",
                                "resnet-34-pytorch",
                                "resnet-50-pytorch",
                                "resnet-50-tf",
                                "resnet18-xnor-binary-onnx-0001",
                                "resnet50-binary-0001",
                                "rexnet-v1-x1.0",
                                "se-inception",
                                "se-resnet-50",
                                "se-resnext-50",
                                "shufflenet-v2-x0.5",
                                "shufflenet-v2-x1.0",
                                "squeezenet1.0",
                                "squeezenet1.1",
                                "swin-tiny-patch4-window7-224",
                                "vgg16",
                                "vgg19"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "Path to a folder with images or path to an image file.",
                    "source": "",
                    "default":"/Source/testing_source/",
                    "argument": "-i"
                },
                {
                    "name": "labels",
                    "required": true,
                    "title": "Select a label file of the classification model",
                    "hint": "Input the index of label file or the Path to .txt file with labels.",
                    "default": "",
                    "argument": "-labels",
                    "items":
                    [
                        {
                            "name": "imagenet_2012.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["*"]
                        },
                        {
                            "name": "imagenet_2015.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["googlenet-v2","se-inception","se-resnet-50","se-resnext-50"]
                        }
                    ]
                },
                {
                    "name": "groundTruth",
                    "required": false,
                    "hint": "Path to ground truth .txt file.",
                    "default": "",
                    "argument": "-gt"
                }
                           
            ]
        },
        {
            "name": "Object Detection C++ Demo",
            "description": "This demo showcases inference of Object Detection networks using Async API. Async API usage can improve overall frame-rate of the application, because rather than wait for inference to complete, the app can continue doing things on the host, while accelerator is busy. ",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "object_detection_demo",
            "modelList": "/demos/object_detection_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Object Detection model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained model.",
                            "default": "ssd_mobilenet_v1_coco",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "ctdet_coco_dlav0_512",
                                "faceboxes-pytorch",
                                "efficientdet-d0-tf",
                                "efficientdet-d1-tf",
                                "face-detection-0200",
                                "face-detection-0202",
                                "face-detection-0204",
                                "face-detection-0205",
                                "face-detection-0206",
                                "face-detection-adas-0001",
                                "face-detection-retail-0004",
                                "face-detection-retail-0005",
                                "face-detection-retail-0044",
                                "faster-rcnn-resnet101-coco-sparse-60-0001",
                                "faster_rcnn_inception_resnet_v2_atrous_coco",
                                "faster_rcnn_resnet50_coco",
                                "pedestrian-and-vehicle-detector-adas-0001",
                                "pedestrian-detection-adas-0002",
                                "pelee-coco",
                                "person-detection-0106",
                                "person-detection-0200",
                                "person-detection-0201",
                                "person-detection-0202",
                                "person-detection-0203",
                                "person-detection-0301",
                                "person-detection-0302",
                                "person-detection-0303",
                                "person-detection-retail-0013",
                                "person-vehicle-bike-detection-2000",
                                "person-vehicle-bike-detection-2001",
                                "person-vehicle-bike-detection-2002",
                                "person-vehicle-bike-detection-2003",
                                "person-vehicle-bike-detection-2004",
                                "product-detection-0001",
                                "retinaface-resnet50-pytorch",
                                "retinanet-tf",
                                "rfcn-resnet101-coco-tf",
                                "ssd300",
                                "ssd512",
                                "ssd-resnet34-1200-onnx",
                                "ssd_mobilenet_v1_coco",
                                "ssd_mobilenet_v1_fpn_coco",
                                "ssdlite_mobilenet_v2",
                                "vehicle-detection-0200",
                                "vehicle-detection-0201",
                                "vehicle-detection-0202",
                                "vehicle-detection-adas-0002",
                                "vehicle-license-plate-detection-barrier-0106",
                                "vehicle-license-plate-detection-barrier-0123",
                                "ultra-lightweight-face-detection-rfb-320",
                                "ultra-lightweight-face-detection-slim-320",
                                "mobilefacedet-v1-mxnet",
                                "mobilenet-yolo-v4-syg",
                                "person-vehicle-bike-detection-crossroad-yolov3-1020",
                                "yolo-v1-tiny-tf",
                                "yolo-v2-ava-0001",
                                "yolo-v2-ava-sparse-35-0001",
                                "yolo-v2-ava-sparse-70-0001",
                                "yolo-v2-tf",
                                "yolo-v2-tiny-ava-0001",
                                "yolo-v2-tiny-ava-sparse-30-0001",
                                "yolo-v2-tiny-ava-sparse-60-0001",
                                "yolo-v2-tiny-tf",
                                "yolo-v2-tiny-vehicle-detection-0001",
                                "yolo-v3-tf",
                                "yolo-v3-tiny-tf",
                                "yolo-v3-onnx",
                                "yolo-v3-tiny-onnx",
                                "yolo-v4-tf",
                                "yolo-v4-tiny-tf",
                                "yolof",
                                "yolox-tiny"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"0",
                    "argument": "-i"
                },
                {
                    "name": "labels",
                    "required": false,
                    "title": "Select a label file of the Object Detection model",
                    "hint": "Input the index of label file or the Path to .txt file with labels.",
                    "default": "",
                    "argument": "--labels",
                    "items":
                    [
                        {
                            "name": "coco_80cl.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["ctdet_coco_dlav0_512","pelee-coco","retinanet-tf","yolo-v2-tf","yolo-v2-tiny-tf","yolo-v3-onnx","yolo-v3-tf","yolo-v3-tiny-onnx","yolo-v3-tiny-tf","yolo-v4-tf","yolo-v4-tiny-tf","yolof","yolox-tiny"]
                        },
                        {
                            "name": "coco_80cl_bkgr.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["faster-rcnn-resnet101-coco-sparse-60-0001","ssd-resnet34-1200-onnx"]
                        },
                        {
                            "name": "coco_91cl.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["efficientdet-d0-tf","efficientdet-d1-tf"]
                        },
                        {
                            "name": "coco_91cl_bkgr.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["faster_rcnn_inception_resnet_v2_atrous_coco","faster_rcnn_resnet50_coco","rfcn-resnet101-coco-tf","ssd_mobilenet_v1_coco","ssd_mobilenet_v1_fpn_coco","ssdlite_mobilenet_v2"]
                        },
                        {
                            "name": "voc_20cl.txt ",
                            "path": "/data/dataset_classes/",
                            "models": ["yolo-v1-tiny-tf"]
                        },
                        {
                            "name": "voc_20cl_bkgr.txt ",
                            "path": "/data/dataset_classes/",
                            "models": ["ssd300","ssd512"]
                        }
                    ]
                },
                {
                    "name": "architecture type",
                    "required": true,
                    "title": "Specify model' architecture type. ",
                    "hint": "Valid values are {ssd,yolo,yolov3-onnx,yolov4,yolof,yolox,faceboxes,centernet,ctpn,retinaface,ultra_lightweight_face_detection,retinaface-pytorch,detr}.",
                    "default": "ssd",
                    "argument": "-at",
                    "items":
                    [
                        {
                            "name": "ssd",
                            "models": 
                            [
                                "efficientdet-d0-tf",
                                "efficientdet-d1-tf",
                                "face-detection-0200",
                                "face-detection-0202",
                                "face-detection-0204",
                                "face-detection-0205",
                                "face-detection-0206",
                                "face-detection-adas-0001",
                                "face-detection-retail-0004",
                                "face-detection-retail-0005",
                                "face-detection-retail-0044",
                                "faster-rcnn-resnet101-coco-sparse-60-0001",
                                "faster_rcnn_inception_resnet_v2_atrous_coco",
                                "faster_rcnn_resnet50_coco",
                                "pedestrian-and-vehicle-detector-adas-0001",
                                "pedestrian-detection-adas-0002",
                                "pelee-coco",
                                "person-detection-0106",
                                "person-detection-0200",
                                "person-detection-0201",
                                "person-detection-0202",
                                "person-detection-0203",
                                "person-detection-0301",
                                "person-detection-0302",
                                "person-detection-0303",
                                "person-detection-retail-0013",
                                "person-vehicle-bike-detection-2000",
                                "person-vehicle-bike-detection-2001",
                                "person-vehicle-bike-detection-2002",
                                "person-vehicle-bike-detection-2003",
                                "person-vehicle-bike-detection-2004",
                                "product-detection-0001",
                                "retinaface-resnet50-pytorch",
                                "retinanet-tf",
                                "rfcn-resnet101-coco-tf",
                                "ssd300",
                                "ssd512",
                                "ssd-resnet34-1200-onnx",
                                "ssd_mobilenet_v1_coco",
                                "ssd_mobilenet_v1_fpn_coco",
                                "ssdlite_mobilenet_v2",
                                "vehicle-detection-0200",
                                "vehicle-detection-0201",
                                "vehicle-detection-0202",
                                "vehicle-detection-adas-0002",
                                "vehicle-license-plate-detection-barrier-0106",
                                "vehicle-license-plate-detection-barrier-0123"
                            ]
                        },
                        {
                            "name": "centernet",
                            "models": 
                            [
                                "ctdet_coco_dlav0_512"
                            ]
                        },
                        {
                            "name": "ctpn",
                            "models": 
                            [
                                "ctpn"
                            ]
                        },
                        {
                            "name": "detr",
                            "models": 
                            [
                                "detr-resnet50"
                            ]
                        },
                        {
                            "name": "faceboxes",
                            "models": 
                            [
                                "faceboxes-pytorch"
                            ]
                        },
                        {
                            "name": "retinaface-pytorch",
                            "models": 
                            [
                                "retinaface-resnet50-pytorch"
                            ]
                        },
                        {
                            "name": "ultra_lightweight_face_detection",
                            "models": 
                            [
                                "ultra-lightweight-face-detection-rfb-320",
                                "ultra-lightweight-face-detection-slim-320"
                            ]
                        },
                        {
                            "name": "yolo",
                            "models": 
                            [
                                "mobilefacedet-v1-mxnet",
                                "mobilenet-yolo-v4-syg",
                                "person-vehicle-bike-detection-crossroad-yolov3-1020",
                                "yolo-v1-tiny-tf",
                                "yolo-v2-ava-0001",
                                "yolo-v2-ava-sparse-35-0001",
                                "yolo-v2-ava-sparse-70-0001",
                                "yolo-v2-tf",
                                "yolo-v2-tiny-ava-0001",
                                "yolo-v2-tiny-ava-sparse-30-0001",
                                "yolo-v2-tiny-ava-sparse-60-0001",
                                "yolo-v2-tiny-tf",
                                "yolo-v2-tiny-vehicle-detection-0001",
                                "yolo-v3-tf",
                                "yolo-v3-tiny-tf"
                            ]
                        },
                        {
                            "name": "yolov3-onnx",
                            "models": 
                            [
                                "yolo-v3-onnx",
                                "yolo-v3-tiny-onnx"
                            ]
                        },
                        {
                            "name": "yolov4",
                            "models": 
                            [
                                "yolo-v4-tf",
                                "yolo-v4-tiny-tf"
                            ]
                        },
                        {
                            "name": "yolof",
                            "models": 
                            [
                                "yolof"
                            ]
                        },
                        {
                            "name": "yolox",
                            "models": 
                            [
                                "yolox-tiny"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "name": "Interactive Face Detection C++ Demo",
            "description": "This demo showcases Object Detection task applied for face recognition using sequence of neural networks. This demo executes five parallel infer requests for the Age/Gender Recognition, Head Pose Estimation, Emotions Recognition, Facial Landmarks Detection and Antispoofing Classifier networks that run simultaneously.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "interactive_face_detection_demo",
            "modelList": "/demos/interactive_face_detection_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Face Detection model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained Face Detection model.",
                            "default": "face-detection-retail-0004",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "face-detection-adas-0001",
                                "face-detection-retail-0004",
                                "face-detection-retail-0005",
                                "face-detection-retail-0044"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Age/Gender Recognition model",
                            "required": false,
                            "hint": "Path to an .xml file with a trained Age/Gender Recognition model.",
                            "default": "age-gender-recognition-retail-0013",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_ag",
                            "device_argument": "",
                            "items": 
                            [
                                "age-gender-recognition-retail-0013"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Head Pose Estimation model",
                            "required": false,
                            "hint": "Path to an .xml file with a trained Head Pose Estimation model.",
                            "default": "head-pose-estimation-adas-0001",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_hp",
                            "device_argument": "",
                            "items": 
                            [
                                "head-pose-estimation-adas-0001"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Emotions Recognition model",
                            "required": false,
                            "hint": "Path to an .xml file with a trained Emotions Recognition model.",
                            "default": "emotions-recognition-retail-0003",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_em",
                            "device_argument": "",
                            "items": 
                            [
                                "emotions-recognition-retail-0003"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Facial Landmarks Estimation model",
                            "required": false,
                            "hint": "Path to an .xml file with a trained Facial Landmarks Estimation model.",
                            "default": "facial-landmarks-35-adas-0002",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_lm",
                            "device_argument": "",
                            "items": 
                            [
                                "facial-landmarks-35-adas-0002"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Antispoofing Classification model",
                            "required": false,
                            "hint": "Path to an .xml file with a trained Antispoofing Classification model.",
                            "default": "anti-spoof-mn3",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_am",
                            "device_argument": "",
                            "items": 
                            [
                                "anti-spoof-mn3"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/head-pose-face-detection-female-and-male.mp4",
                    "default":"/Source/testing_source/head-pose-face-detection-female-and-male.mp4",
                    "argument": "-i"
                }                
            ]
        },
        {
            "name": "Human Pose Estimation C++ Demo",
            "description": "This demo showcases the work of multi-person 2D pose estimation algorithm. The task is to predict a pose: body skeleton, which consists of keypoints and connections between them, for every person in an input video. The pose may contain up to 18 keypoints: ears, eyes, nose, neck, shoulders, elbows, wrists, hips, knees, and ankles. Some of potential use cases of the algorithm are action recognition and behavior understanding.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "human_pose_estimation_demo",
            "modelList": "/demos/human_pose_estimation_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Pose Estimation model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained model.",
                            "default": "human-pose-estimation-0001",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "human-pose-estimation-0001",
                                "human-pose-estimation-0005",
                                "human-pose-estimation-0006",
                                "human-pose-estimation-0007",
                                "higher-hrnet-w32-human-pose-estimation"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"0",
                    "argument": "-i"
                },
                {
                    "name": "architecture type",
                    "required": true,
                    "title": "Type of the model, either 'ae' for Associative Embedding, 'higherhrnet' for HigherHRNet models based on ae or 'openpose' for OpenPose.",
                    "hint": "",
                    "default": "openpose",
                    "argument": "-at",
                    "items":
                    [
                        {
                            "name": "openpose",
                            "models": 
                            [
                                "human-pose-estimation-0001"
                            ]
                        },
                        {
                            "name": "ae",
                            "models": 
                            [
                                "human-pose-estimation-0005",
                                "human-pose-estimation-0006",
                                "human-pose-estimation-0007"

                            ]
                        },
                        {
                            "name": "higherhrnet",
                            "models": 
                            [
                                "higher-hrnet-w32-human-pose-estimation"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "name": "3D Human Pose Estimation Python* Demo",
            "description": "This demo showcases the work of multi-person 2D pose estimation algorithm. The task is to predict a pose: body skeleton, which consists of keypoints and connections between them, for every person in an input video. The pose may contain up to 18 keypoints: ears, eyes, nose, neck, shoulders, elbows, wrists, hips, knees, and ankles. Some of potential use cases of the algorithm are action recognition and behavior understanding.",
            "path": "~/open_model_zoo-2022.1.0/demos/human_pose_estimation_3d_demo/python",
            "appName": "human_pose_estimation_3d_demo.py",
            "modelList": "/demos/human_pose_estimation_3d_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Pose Estimation model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained model.",
                            "default": "human-pose-estimation-3d-0001",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "human-pose-estimation-3d-0001"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/people-detection.mp4",
                    "default":"/Source/testing_source/people-detection.mp4",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "Crossroad Camera C++ Demo",
            "description": "This demo provides an inference pipeline for person detection, recognition and reidentification. The demo uses a Person Detection network followed by the Person Attributes Recognition and Person Reidentification Retail networks applied on top of the detection results. ",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "crossroad_camera_demo",
            "modelList": "/demos/crossroad_camera_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Person/Vehicle/Bike Detection Crossroad model",
                            "required": true,
                            "hint": "Select a Person/Vehicle/Bike Detection Crossroad model",
                            "default": "person-vehicle-bike-detection-crossroad-0078",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "person-vehicle-bike-detection-crossroad-0078",
                                "person-vehicle-bike-detection-crossroad-1016"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Person Attributes Recognition Crossroad model",
                            "required": false,
                            "hint": "Select a Person Attributes Recognition Crossroad model",
                            "default": "person-attributes-recognition-crossroad-0230",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m_pa",
                            "device_argument": "-d_pa",
                            "items": 
                            [
                                "person-attributes-recognition-crossroad-0230",
                                "person-attributes-recognition-crossroad-0234",
                                "person-attributes-recognition-crossroad-0238"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Person Reidentification Retail model",
                            "required": false,
                            "hint": "Select a Person Reidentification Retail model",
                            "default": "person-reidentification-retail-0277",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m_reid",
                            "device_argument": "-d_reid",
                            "items": 
                            [
                                "person-reidentification-retail-0277",
                                "person-reidentification-retail-0286",
                                "person-reidentification-retail-0287",
                                "person-reidentification-retail-0288"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/people-detection.mp4",
                    "default":"/Source/testing_source/people-detection.mp4",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "Social Distance C++ Demo",
            "description": "This demo showcases a retail social distance application that detects people and measures the distance between them. If this distance is less than a value previously provided by the user, then an alert is triggered.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "social_distance_demo",
            "modelList": "/demos/social_distance_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Person Detection model",
                            "required": true,
                            "hint": "Select a Person Detection model",
                            "default": "person-detection-retail-0013",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m_det",
                            "device_argument": "-d_det",
                            "items": 
                            [
                                "person-detection-0200",
                                "person-detection-0201",
                                "person-detection-0202",
                                "person-detection-retail-0013"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Person Reidentification Retail model",
                            "required": false,
                            "hint": "Select a Person Reidentification Retail model",
                            "default": "person-reidentification-retail-0277",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m_reid",
                            "device_argument": "-d_reid",
                            "items": 
                            [
                                "person-reidentification-retail-0277",
                                "person-reidentification-retail-0286",
                                "person-reidentification-retail-0287",
                                "person-reidentification-retail-0288"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be Path to video or image files.",
                    "source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/people-detection.mp4",
                    "default":"/Source/testing_source/people-detection.mp4",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "Pedestrian Tracker C++ Demo",
            "description": "This demo showcases Pedestrian Tracking scenario: it reads frames from an input video sequence, detects pedestrians in the frames, and builds trajectories of movement of the pedestrians in a frame-by-frame manner.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "pedestrian_tracker_demo",
            "modelList": "/demos/pedestrian_tracker_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "-loop",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Pedestrian Detection Retail model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained Pedestrian Detection Retail model.",
                            "default": "person-detection-retail-0013",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m_det",
                            "device_argument": "-d_det",
                            "items": 
                            [
                                "ctdet_coco_dlav0_512",
                                "efficientdet-d0-tf",
                                "efficientdet-d1-tf",
                                "faster-rcnn-resnet101-coco-sparse-60-0001",
                                "pedestrian-and-vehicle-detector-adas-0001",
                                "pedestrian-detection-adas-0002",
                                "pelee-coco",
                                "person-detection-0106",
                                "person-detection-0200",
                                "person-detection-0201",
                                "person-detection-0202",
                                "person-detection-0203",
                                "person-detection-retail-0002",
                                "person-detection-retail-0013",
                                "person-vehicle-bike-detection-2000",
                                "person-vehicle-bike-detection-2001",
                                "person-vehicle-bike-detection-2002",
                                "person-vehicle-bike-detection-2003",
                                "person-vehicle-bike-detection-2004",
                                "rfcn-resnet101-coco-tf",
                                "retinanet-tf",
                                "ssd300",
                                "ssd512",
                                "ssd-resnet34-1200-onnx",
                                "ssd_mobilenet_v1_coco",
                                "ssd_mobilenet_v1_fpn_coco",
                                "ssdlite_mobilenet_v2",
                                "vehicle-detection-adas-0002",
                                "person-vehicle-bike-detection-crossroad-yolov3-1020",
                                "yolo-v3-tf",
                                "yolo-v3-tiny-tf",
                                "yolo-v1-tiny-tf",
                                "yolo-v2-ava-0001",
                                "yolo-v2-ava-sparse-35-0001",
                                "yolo-v2-ava-sparse-70-0001",
                                "yolo-v2-tf",
                                "yolo-v2-tiny-ava-0001",
                                "yolo-v2-tiny-ava-sparse-30-0001",
                                "yolo-v2-tiny-ava-sparse-60-0001",
                                "yolo-v2-tiny-tf",
                                "yolo-v2-tiny-vehicle-detection-0001"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Pedestrian Reidentification Retail model",
                            "required": true,
                            "hint": "Path to an .xml file with a trained Pedestrian Reidentification Retail model.",
                            "default": "person-reidentification-retail-0277",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m_reid",
                            "device_argument": "-d_reid",
                            "items": 
                            [
                                "person-reidentification-retail-0277",
                                "person-reidentification-retail-0286",
                                "person-reidentification-retail-0287",
                                "person-reidentification-retail-0288"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/people-detection.mp4",
                    "default":"/Source/testing_source/people-detection.mp4",
                    "argument": "-i"
                },
                {
                    "name": "architecture type",
                    "required": true,
                    "title": "Type of the model, either 'ae' for Associative Embedding, 'higherhrnet' for HigherHRNet models based on ae or 'openpose' for OpenPose.",
                    "hint": "",
                    "default": "openpose",
                    "argument": "-at",
                    "items":
                    [
                        {
                            "name": "centernet",
                            "models": 
                            [
                                "ctdet_coco_dlav0_512"
                            ]
                        },
                        {
                            "name": "ssd",
                            "models": 
                            [
                                "efficientdet-d0-tf",
                                "efficientdet-d1-tf",
                                "faster-rcnn-resnet101-coco-sparse-60-0001",
                                "pedestrian-and-vehicle-detector-adas-0001",
                                "pedestrian-detection-adas-0002",
                                "pelee-coco",
                                "person-detection-0106",
                                "person-detection-0200",
                                "person-detection-0201",
                                "person-detection-0202",
                                "person-detection-0203",
                                "person-detection-retail-0002",
                                "person-detection-retail-0013",
                                "person-vehicle-bike-detection-2000",
                                "person-vehicle-bike-detection-2001",
                                "person-vehicle-bike-detection-2002",
                                "person-vehicle-bike-detection-2003",
                                "person-vehicle-bike-detection-2004",
                                "rfcn-resnet101-coco-tf",
                                "retinanet-tf",
                                "ssd300",
                                "ssd512",
                                "ssd-resnet34-1200-onnx",
                                "ssd_mobilenet_v1_coco",
                                "ssd_mobilenet_v1_fpn_coco",
                                "ssdlite_mobilenet_v2",
                                "vehicle-detection-adas-0002"

                            ]
                        },
                        {
                            "name": "yolo",
                            "models": 
                            [
                                "person-vehicle-bike-detection-crossroad-yolov3-1020",
                                "yolo-v3-tf",
                                "yolo-v3-tiny-tf",
                                "yolo-v1-tiny-tf",
                                "yolo-v2-ava-0001",
                                "yolo-v2-ava-sparse-35-0001",
                                "yolo-v2-ava-sparse-70-0001",
                                "yolo-v2-tf",
                                "yolo-v2-tiny-ava-0001",
                                "yolo-v2-tiny-ava-sparse-30-0001",
                                "yolo-v2-tiny-ava-sparse-60-0001",
                                "yolo-v2-tiny-tf",
                                "yolo-v2-tiny-vehicle-detection-0001"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "name": "Background subtraction Python* Demo",
            "description": "This demo shows how to perform background subtraction using OpenVINO.",
            "path": "~/open_model_zoo-2022.1.0/demos/background_subtraction_demo/python",
            "appName": "background_subtraction_demo.py",
            "modelList": "/demos/background_subtraction_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Background subtraction",
                            "required": true,
                            "hint": "Path to an .xml file with a trained model.",
                            "default": "instance-segmentation-person-0007",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "instance-segmentation-person-",
                                "yolact-resnet50-fpn-pytorch"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/head-pose-face-detection-female-and-male.mp4",
                    "default":"/Source/testing_source/head-pose-face-detection-female-and-male.mp4",
                    "argument": "-i"
                },
                {
                    "name": "Background Image",
                    "required": false,
                    "hint": "If you specify --target_bgr, background will be replaced by a chosen image or video. By default background replaced by green field. Please input the path to an image/video.",
                    "default":"",
                    "argument": "--target_bgr"
                },
                {
                    "name": "Background blurred",
                    "required": false,
                    "hint": "If you specify --blur_bgr, background will be blurred according to a set value. By default equal to zero and is not applied. Please Input a number. ",
                    "default":"",
                    "argument": "--blur_bgr"
                }
            ]
        },
        {
            "name": "Text Detection C++ Demo",
            "description": "The demo shows an example of using neural networks to detect and recognize printed text rotated at any angle in various environment. ",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "text_detection_demo",
            "modelList": "/demos/text_detection_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Text Detection model",
                            "required": true,
                            "hint": "Path to the Text Detection model (.xml) file.",
                            "default": "text-detection-0004",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m_td",
                            "device_argument": "-d_td",
                            "items": 
                            [
                                "horizontal-text-detection-0001",
                                "text-detection-0003",
                                "text-detection-0004"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Text Recognition model",
                            "required": true,
                            "hint": "Path to the Text Recognition model (.xml) file.",
                            "default": "text-recognition-0014",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m_tr",
                            "device_argument": "-d_tr",
                            "items": 
                            [
                                "handwritten-score-recognition-0003",
                                "text-recognition-0012",
                                "text-recognition-0014",
                                "text-recognition-0015",
                                "text-recognition-0016",
                                "text-recognition-resnet-fc",
                                "vitstr-small-patch16-224"
                            ],
                            "ban":
                            [
                                "decoder"
                            ]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"0",
                    "argument": "-i"
                },
                {
                    "name": "architecture type",
                    "required": false,
                    "title": "Type of the decoder",
                    "hint": "either 'simple' for SimpleDecoder or 'ctc' for CTC greedy and CTC beam search decoders. Default is 'ctc'",
                    "default": "ctc",
                    "argument": "-dt",
                    "items":
                    [
                        {
                            "name": "ctc",
                            "models": 
                            [
                                "text-recognition-0012",
                                "text-recognition-0014"
                            ]
                        },
                        {
                            "name": "simple",
                            "models": 
                            [
                                "text-recognition-0015",
                                "text-recognition-0016",
                                "text-recognition-resnet-fc",
                                "vitstr-small-patch16-224"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "name": "Image Processing C++ Demo - Super Resolution",
            "description": "This demo processes the image according to the selected type of processing.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "image_processing_demo",
            "modelList": "/demos/image_processing_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "-at sr",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Super Resolution model",
                            "required": true,
                            "hint": "Path to an .xml file with a Super Resolution model.",
                            "default": "single-image-super-resolution-1032",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "single-image-super-resolution-1032",
                                "single-image-super-resolution-1033",
                                "text-image-super-resolution-0001"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"/Source/testing_source/SanChungBus_Route306_620FG_wide.jpg",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "Image Processing C++ Demo - Style Transfer",
            "description": "This demo processes the image according to the selected type of processing. For style_transfer, user can use fast-neural-style-mosaic-onnx - one of the style transfer models designed to mix the content of an image with the style of another image.",
            "path": "~/omz_demos_build/intel64/Release",
            "appName": "image_processing_demo",
            "modelList": "/demos/image_processing_demo/cpp/models.lst",
            "preprocess": "",
            "postprocess": "-at style",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Super Resolution model",
                            "required": true,
                            "hint": "Path to an .xml file with a Super Resolution model.",
                            "default": "fast-neural-style-mosaic-onnx",
                            "default_precisions": "FP16",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "fast-neural-style-mosaic-onnx"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"/Source/testing_source/budgie.jpg",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "Colorization Demo",
            "description": "This demo demonstrates an example of using neural networks to colorize a grayscale image or video.",
            "path": "~/open_model_zoo-2022.1.0/demos/colorization_demo/python",
            "appName": "colorization_demo.py",
            "modelList": "/demos/colorization_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "--loop",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Colorization model",
                            "required": true,
                            "hint": "Path to an .xml file with a Colorization model.",
                            "default": "colorization-v2",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "colorization-v2",
                                "colorization-siggraph"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"/Source/testing_source/1960s_Taiwan_Taichung.jpg",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "MonoDepth Python Demo",
            "description": "This topic demonstrates how to run the MonoDepth demo application, which produces a disparity map for a given input image. To this end, the code uses the network described in Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer.",
            "path": "~/open_model_zoo-2022.1.0/demos/monodepth_demo/python",
            "appName": "monodepth_demo.py",
            "modelList": "/demos/monodepth_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "--loop",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "MonoDepth model",
                            "required": true,
                            "hint": "Path to an .xml file with a MonoDepth model.",
                            "default": "midasnet",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "midasnet",
                                "fcrn-dp-nyu-depth-v2-tf"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be a single image, a folder of images, video file or camera id.",
                    "source": "",
                    "default":"/Source/testing_source/1960s_Taiwan_Taichung.jpg",
                    "argument": "-i"
                }
            ]
        },
        {
            "name": "Sound Classification Python Demo",
            "description": "This is a demo application for sound classification algorithm.",
            "path": "~/open_model_zoo-2022.1.0/demos/sound_classification_demo/python",
            "appName": "sound_classification_demo.py",
            "modelList": "/demos/sound_classification_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Sound Classification model",
                            "required": true,
                            "hint": "Path to an .xml file with a Sound Classification model.",
                            "default": "aclnet",
                            "default_precisions": "FP32",
                            "default_device": "AUTO",
                            "argument": "-m",
                            "device_argument": "-d",
                            "items": 
                            [
                                "aclnet",
                                "aclnet-int8"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "An input to process. The input must be audio files in wav format.",
                    "source": "",
                    "default":"",
                    "argument": "-i"
                },
                {
                    "name": "labels",
                    "required": false,
                    "title": "Select a label file of the Sound Classification model",
                    "hint": "Input the index of label file or the Path to .txt file with labels.",
                    "default": "aclnet_53cl.txt",
                    "argument": "--labels",
                    "items":
                    [
                        {
                            "name": "aclnet_53cl.txt",
                            "path": "/data/dataset_classes/",
                            "models": ["aclnet"]
                        }
                    ]
                },
                {
                    "name": "Sample Rate",
                    "required": true,
                    "hint": "Set sample rate for audio input",
                    "source": "",
                    "default":"44100",
                    "argument": "-sr"
                }
            ]
        },
        {
            "name": "Text-to-speech Python Demo",
            "description": "The text to speech demo shows how to run the ForwardTacotron and WaveRNN models or modified ForwardTacotron and MelGAN models to produce an audio file for a given input text file.",
            "path": "~/open_model_zoo-2022.1.0/demos/text_to_speech_demo/python",
            "appName": "text_to_speech_demo.py",
            "modelList": "/demos/text_to_speech_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Sound Classification model - ForwardTacotron`s duration prediction part",
                            "required": true,
                            "hint": "Path to ForwardTacotron`s duration prediction part",
                            "default": "text-to-speech-en-0001-duration-prediction",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m_duration",
                            "device_argument": "-d",
                            "items": 
                            [
                                "text-to-speech-en-0001-duration-prediction"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Sound Classification model - ForwardTacotron`s mel-spectrogram regression part",
                            "required": true,
                            "hint": "Path to ForwardTacotron`s mel-spectrogram regression part model",
                            "default": "text-to-speech-en-0001-regression",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_forward",
                            "device_argument": "",
                            "items": 
                            [
                                "text-to-speech-en-0001-regression"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Sound Classification model - WaveRNN`s part for mel-spectrogram upsampling by time axis",
                            "required": true,
                            "hint": "Path to WaveRNN`s part for mel-spectrogram upsampling by time axis model",
                            "default": "text-to-speech-en-0001-generation",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_melgan",
                            "device_argument": "",
                            "items": 
                            [
                                "text-to-speech-en-0001-generation"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "Text or path to the input file.",
                    "source": "",
                    "default":"/Source/testing_source/speech_text.txt",
                    "argument": "-i"
                },
                {
                    "name": "output",
                    "required": true,
                    "hint": "Path to an output .wav file.",
                    "source": "",
                    "default":"",
                    "argument": "-o"
                }
            ]
        },
        {
            "name": "Text-to-speech Python Demo (Multi)",
            "description": "The text to speech demo shows how to run the ForwardTacotron and WaveRNN models or modified ForwardTacotron and MelGAN models to produce an audio file for a given input text file.",
            "path": "~/open_model_zoo-2022.1.0/demos/text_to_speech_demo/python",
            "appName": "text_to_speech_demo.py",
            "modelList": "/demos/text_to_speech_demo/python/models.lst",
            "preprocess": "export PYTHONPATH=\"$PYTHONPATH:$HOME/omz_demos_build/intel64/Release\" && ",
            "postprocess": "-s_id -1",
            "setting":
            [
                {
                    "name": "model",
                    "required": true,
                    "items":
                    [
                        {
                            "name": "Sound Classification model - ForwardTacotron`s duration prediction part",
                            "required": true,
                            "hint": "Path to ForwardTacotron`s duration prediction part",
                            "default": "text-to-speech-en-multi-0001-duration-prediction",
                            "default_precisions": "FP32",
                            "default_device": "CPU",
                            "argument": "-m_duration",
                            "device_argument": "-d",
                            "items": 
                            [
                                "text-to-speech-en-multi-0001-duration-prediction"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Sound Classification model - ForwardTacotron`s mel-spectrogram regression part",
                            "required": true,
                            "hint": "Path to ForwardTacotron`s mel-spectrogram regression part model",
                            "default": "text-to-speech-en-multi-0001-regression",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_forward",
                            "device_argument": "",
                            "items": 
                            [
                                "text-to-speech-en-multi-0001-regression"
                            ],
                            "ban":[]
                        },
                        {
                            "name": "Sound Classification model - WaveRNN`s part for mel-spectrogram upsampling by time axis",
                            "required": true,
                            "hint": "Path to WaveRNN`s part for mel-spectrogram upsampling by time axis model",
                            "default": "text-to-speech-en-multi-0001-generation",
                            "default_precisions": "FP32",
                            "default_device": "",
                            "argument": "-m_melgan",
                            "device_argument": "",
                            "items": 
                            [
                                "text-to-speech-en-multi-0001-generation"
                            ],
                            "ban":[]
                        }
                    ]
                },
                {
                    "name": "input",
                    "required": true,
                    "hint": "Text or path to the input file.",
                    "source": "",
                    "default":"/Source/testing_source/speech_text.txt",
                    "argument": "-i"
                },
                {
                    "name": "output",
                    "required": true,
                    "hint": "Path to an output .wav file.",
                    "source": "",
                    "default":"",
                    "argument": "-o"
                }
            ]
        }
    ]
}