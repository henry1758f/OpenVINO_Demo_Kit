{
	"version": "7.0.0",
	"openvinoVersion": "2021.4.582",
	"modelPath": "openvino_models/models/SYNNEX_demo/",
	"publicIrPath": "openvino_models/ir/",
	"demos": [
		{
			"name": "Security Barrier Camera Demo",
			"path": "$DEMO_LOC/",
			"fileName": "security_barrier_camera_demo",
			"InputArguments": " -i ",
			"InputHints": " Input the Path to video or image files ",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Default Picture",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/demo/car_1.bmp"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Vehicle and License Plate Detection model",
					"keywords": ["vehicle-license-plate-detection-barrier"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "vehicle-license-plate-detection-barrier-0106",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_va",
					"devicearguments": "-d_va",
					"usage": "Vehicle and License Plate Detection model",
					"keywords": ["vehicle-attributes-recognition-barrier"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "vehicle-attributes-recognition-barrier-0042",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_lpr",
					"devicearguments": "-d_lpr",
					"usage": "Vehicle and License Plate Detection model",
					"keywords": ["license-plate-recognition-barrier"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "license-plate-recognition-barrier-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Interactive Face Detection Demo",
			"path": "$DEMO_LOC/",
			"fileName": "interactive_face_detection_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "-async",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Face Detection model",
					"keywords": ["face-detection-adas","face-detection"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "face-detection-adas-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_ag",
					"devicearguments": "-d_ag",
					"usage": "Age/Gender Recognition model",
					"keywords": ["age-gender-recognition"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "age-gender-recognition-retail-0013",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_hp",
					"devicearguments": "-d_hp",
					"usage": "Head Pose Estimation model",
					"keywords": ["head-pose-estimation"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "head-pose-estimation-adas-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_em",
					"devicearguments": "-d_em",
					"usage": "Emotions Recognition model",
					"keywords": ["emotions-recognition"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "emotions-recognition-retail-0003",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_lm",
					"devicearguments": "-d_lm",
					"usage": "Facial Landmarks Estimation model",
					"keywords": ["facial-landmarks"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "facial-landmarks-35-adas-0002",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_am",
					"devicearguments": "-d_am",
					"usage": "Antispoofing Classification model",
					"keywords": ["anti-spoof"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "anti-spoof-mn3",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Classification Demo",
			"path": "$DEMO_LOC/",
			"fileName": "classification_demo",
			"InputArguments": " -i ",
			"InputHints": " Input the Path to video or image files ",
			"addArguments": "-u CDM -res 1280x720",
			"defaultInputs":[
				{
					"default": true,
					"name": "Default Picture",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/demo/car.png"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Classification model",
					"keywords": ["classification"],
					"keywordsType": "task_type",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "squeezenet1.1",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"labels":[
				{
					"name": "imagenet_2015.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/imagenet_2015.txt",
					"applyModels": [ "googlenet-v2", "se-inception", "se-resnet-101", "se-resnet-152", "se-resnet-50", "se-resnext-101", "se-resnext-50"],
					"default": false
				},
				{
					"name": "imagenet_2012.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/imagenet_2012.txt",
					"applyModels": [],
					"default": true
				}
			]
		},
		{
			"name": "Object Detection Demo",
			"path": "$DEMO_LOC/",
			"fileName": "object_detection_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id ",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Object Detection model",
					"keywords": ["detection"],
					"keywordsType": "task_type",
					"banlist": ["yolo-v4","mtcnn","f3net","ctpn","ultra-lightweight-face-detection"],
					"required": true,
					"directRun": true,
					"default": {
						"name": "ssd_mobilenet_v2_coco",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"labels":[
				{
					"name": "coco_91cl_bkgr.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_91cl_bkgr.txt",
					"applyModels": [ "ssd_mobilenet_v","ssd_resnet50_v1_fpn_coco"],
					"default": true
				},
				{
					"name": "coco_80cl_bkgr.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_80cl_bkgr.txt",
					"applyModels": [],
					"default": false
				},
				{
					"name": "voc_20cl_bkgr.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/voc_20cl_bkgr.txt",
					"applyModels": ["ssd300","ssd512"],
					"default": false
				},
				{
					"name": "coco_91cl.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_91cl.txt",
					"applyModels": ["ctdet_coco_dlav0"],
					"default": false
				},
				{
					"name": "coco_80cl.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_80cl.txt",
					"applyModels": ["yolo"],
					"default": false
				},
				{
					"name": "voc_20cl.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/voc_20cl.txt",
					"applyModels": [],
					"default": false
				}
			],
			"archType":[
				{
					"name": "centernet",
					"models": ["ctdet_coco_dlav0"],
					"argument": "centernet"
				},
				{
					"name": "faceboxes",
					"models": ["faceboxes-pytorch"],
					"argument": "faceboxes"
				},
				{
					"name": "ssd",
					"models": [
						"efficientdet",
						"face-detection",
						"faster-rcnn-resnet101-coco-sparse-60-0001",
						"pedestrian-and-vehicle-detector-adas-0001",
						"pedestrian-detection-adas-0002",
						"pelee-coco",
						"person-detection",
						"person-vehicle-bike-detection",
						"product-detection-0001",
						"rfcn-resnet101-coco-tf",
						"retinanet-tf",
						"ssd",
						"vehicle-detection",
						"vehicle-license-plate-detection-barrier"
					],
					"argument": "ssd"
				},
				{
					"name": "yolo",
					"models": ["yolo-v3","yolov3"],
					"argument": "yolo"
				}
			]
		},
		{
			"name": "Human Pose Estimation Demo. (2D)",
			"path": "$DEMO_LOC/",
			"fileName": "human_pose_estimation_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Pose Estimation Model",
					"keywords": ["human-pose-estimation-0001","human-pose-estimation-0005","human-pose-estimation-0006","human-pose-estimation-0007","higher-hrnet-w32-human-pose-estimation"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "human-pose-estimation-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"archType":[
				{
					"name": "openpose",
					"models": ["human-pose-estimation-0001"],
					"argument": "openpose"
				},
				{
					"name": "ae",
					"models": ["human-pose-estimation-0005","human-pose-estimation-0006","human-pose-estimation-0007"],
					"argument": "ae"
				},
				{
					"name": "higherhrnet",
					"models": ["higher-hrnet-w32-human-pose-estimation"],
					"argument": "higherhrnet"
				}
			]
		},
		{
			"name": "Human Pose Estimation Demo. (3D)",
			"path": "${INTEL_OPENVINO_DIR}/inference_engine/demos/human_pose_estimation_3d_demo/python/",
			"fileName": "human_pose_estimation_3d_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "3D Pose Estimation Model",
					"keywords": ["human-pose-estimation-3d-0001"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "human-pose-estimation-3d-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Crossroad Camera Demo",
			"path": "$DEMO_LOC/",
			"fileName": "crossroad_camera_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Person/Vehicle/Bike Detection Crossroad model",
					"keywords": ["person-vehicle-bike-detection-crossroad"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "person-vehicle-bike-detection-crossroad-0078",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_pa",
					"devicearguments": "-d_pa",
					"usage": "Person Attributes Recognition Crossroad model",
					"keywords": ["person-attributes-recognition-crossroad"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "person-attributes-recognition-crossroad-0230",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_reid",
					"devicearguments": "-d_reid",
					"usage": "Person Reidentification Retail model",
					"keywords": ["person-reidentification-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "person-reidentification-retail-0287",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Image Processing Demo",
			"path": "$DEMO_LOC/",
			"fileName": "image_processing_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "0"
				},
				{
					"default": true,
					"name": "[480x270] Photo of a Citybus in Taiwan [70kB] (from Wikipedia by Rico Shen)",
					"fileName": "SanChungBus_Route306_620FG_wide.jpg",
					"path": "<DOWNLOAD>/SanChungBus_Route306_620FG_wide.jpg",
					"source": "https://upload.wikimedia.org/wikipedia/commons/5/51/SanChungBus_Route306_620FG_wide.jpg"
				},{
					"default": false,
					"name": "[640x360] Photo of a Citybus in Taiwan [92kB] (from Wikipedia by Ian871112)",
					"fileName": "640px-20180402_091550_KKA-2591.jpg",
					"path": "<DOWNLOAD>/640px-20180402_091550_KKA-2591.jpg",
					"source": "https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/20180402_091550_KKA-2591.jpg/640px-20180402_091550_KKA-2591.jpg"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Super Resolution Model or Deblur Model",
					"keywords": ["image-super-resolution","deblurgan"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "single-image-super-resolution-1033",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"archType":[
				{
					"name": "Super Resolution",
					"models": ["image-super-resolution"],
					"argument": "sr"
				},
				{
					"name": "Deblurring",
					"models": ["deblurgan"],
					"argument": "deblur"
				}
			]
		},
		{
			"name": "Pedestrian tracker demo",
			"path": "$DEMO_LOC/",
			"fileName": "pedestrian_tracker_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "-delay 30 -loop",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "0"
				},
				{
					"default": true,
					"name": "Sample Video for People Detection [5.2MB] (from GitHub by intel-iot-devkit/sample-videos)",
					"fileName": "people-detection.mp4",
					"path": "<DOWNLOAD>/people-detection.mp4",
					"source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/people-detection.mp4"
				}
			],
			"models": [
				{
					"argument": "-m_det",
					"devicearguments": "-d_det",
					"usage": "Pedestrian Detection Retail model",
					"keywords": ["person-detection-retail","pedestrian-detection","pedestrian-and-vehicle-detector","person-vehicle-bike-detection"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "person-detection-retail-0013",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_reid",
					"devicearguments": "-d_reid",
					"usage": "Pedestrian Reidentification Retail model",
					"keywords": ["person-reidentification"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "person-reidentification-retail-0287",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Smart Classroom Demo",
			"path": "$DEMO_LOC/",
			"fileName": "smart_classroom_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "0"
				},
				{
					"default": true,
					"name": "Sample Video for Classroom Scenario [12.9MB] (from GitHub by intel-iot-devkit/sample-videos)",
					"fileName": "classroom.mp4",
					"path": "<DOWNLOAD>/classroom.mp4",
					"source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/classroom.mp4"
				}
			],
			"models": [
				{
					"argument": "-m_fd",
					"devicearguments": "-d_fd",
					"usage": "Face Detection model",
					"keywords": ["face-detection-adas","face-detection-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "face-detection-adas-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_act",
					"devicearguments": "-d_act",
					"usage": "Person/Action Detection Retail model",
					"keywords": ["person-detection-action-recognition","person-detection-raisinghand-recognition"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "person-detection-action-recognition-0005",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_lm",
					"devicearguments": "-d_lm",
					"usage": "Facial Landmarks Regression Retail model",
					"keywords": ["landmarks-regression-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "landmarks-regression-retail-0009",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				
				{
					"argument": "-m_reid",
					"devicearguments": "-d_reid",
					"usage": "Face Reidentification Retail model",
					"keywords": ["face-reidentification-retail","Sphereface"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "face-reidentification-retail-0095",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Image Segmentation Demo",
			"path": "$DEMO_LOC/",
			"fileName": "segmentation_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Image segmentation model",
					"keywords": ["deeplabv3","fastseg","hrnet-v2-c1-segmentation","icnet-camvid-ava","pspnet-pytorch","road-segmentation","semantic-segmentation","unet-camvid-onnx"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "semantic-segmentation-adas-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Instance Segmentation Demo",
			"path": "${INTEL_OPENVINO_DIR}/inference_engine/demos/instance_segmentation_demo/python/",
			"fileName": "instance_segmentation_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "--no_keep_aspect_ratio --delay 1",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "0"
				},
				{
					"default": true,
					"name": "Sample Video for Classroom Scenario [12.9MB] (from GitHub by intel-iot-devkit/sample-videos)",
					"fileName": "classroom.mp4",
					"path": "<DOWNLOAD>/classroom.mp4",
					"source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/classroom.mp4"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "instance segmentation model",
					"keywords": ["instance-segmentation","yolact-resnet50-fpn-pytorch"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "instance-segmentation-security-0228",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"labels":[
				{
					"name": "coco_91cl_bkgr.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_91cl_bkgr.txt",
					"applyModels": [],
					"default": false
				},
				{
					"name": "coco_80cl_bkgr.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_80cl_bkgr.txt",
					"applyModels": [],
					"default": true
				},
				{
					"name": "voc_20cl_bkgr.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/voc_20cl_bkgr.txt",
					"applyModels": [],
					"default": false
				},
				{
					"name": "coco_91cl.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_91cl.txt",
					"applyModels": [],
					"default": false
				},
				{
					"name": "coco_80cl.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/coco_80cl.txt",
					"applyModels": [],
					"default": false
				},
				{
					"name": "voc_20cl.txt",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/voc_20cl.txt",
					"applyModels": [],
					"default": false
				}
			]
		},
		{
			"name": "Gaze Estimation Demo",
			"path": "$DEMO_LOC/",
			"fileName": "gaze_estimation_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Gaze Estimation model",
					"keywords": ["gaze-estimation"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "gaze-estimation-adas-0002",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_fd",
					"devicearguments": "-d_fd",
					"usage": "Face Detection model",
					"keywords": ["face-detection-adas","face-detection-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "face-detection-retail-0004",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_hp",
					"devicearguments": "-d_hp",
					"usage": "Head Pose Estimation model",
					"keywords": ["head-pose-estimation-adas-0001"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "head-pose-estimation-adas-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_lm",
					"devicearguments": "-d_lm",
					"usage": "Facial Landmarks Estimation model",
					"keywords": ["facial-landmarks"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "facial-landmarks-35-adas-0002",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_es",
					"devicearguments": "-d_es",
					"usage": "Open/Closed Eye Estimation model",
					"keywords": ["open-closed-eye"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "open-closed-eye-0001",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Text Detection Demo",
			"path": "$DEMO_LOC/",
			"fileName": "text_detection_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m_td",
					"devicearguments": "-d_td",
					"usage": "Text Detection model",
					"keywords": ["text-detection"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "text-detection-0003",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_tr",
					"devicearguments": "-d_tr",
					"usage": "Text Recognition model",
					"keywords": ["text-recognition"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "text-recognition-0012",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"archType":[
				{
					"name": "SimpleDecoder",
					"models": ["text-recognition-resnet-fc","text-recognition-0015"],
					"argument": "simple"
				},
				{
					"name": "CTC greedy and CTC beam search decoders",
					"models": ["deblurgan"],
					"argument": "ctc"
				}
			]
		},
		{
			"name": "Text Spotting Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/text_spotting_demo/python/",
			"fileName": "text_spotting_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m_m",
					"devicearguments": "-d",
					"usage": "trained Mask-RCNN model with additional text features output",
					"keywords": ["text-spotting-0005-detector"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "text-spotting-0005-detector",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_te",
					"devicearguments": "",
					"usage": "Trained text recognition model (encoder part)",
					"keywords": ["text-spotting-0005-recognizer-encoder"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "text-spotting-0005-recognizer-encoder",
						"device": "",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_td",
					"devicearguments": "",
					"usage": "Trained text recognition model (encoder part)",
					"keywords": ["text-spotting-0005-recognizer-decoder"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "text-spotting-0005-recognizer-decoder",
						"device": "",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Action Recognition Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/action_recognition_demo/python/",
			"fileName": "action_recognition_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "0"
				},
				{
					"default": true,
					"name": "Sample Video for Driver actions [51.3MB] (from GitHub by vadimar/sample-videos)",
					"fileName": "driver-action-recognition.mp4",
					"path": "<DOWNLOAD>/driver-action-recognition.mp4",
					"source": "https://raw.githubusercontent.com/vadimadr/sample-videos/va/add_action_recognition_sample/driver-action-recognition.mp4"
				}
			],
			"models": [
				{
					"argument": "-m_en",
					"devicearguments": "-d",
					"usage": "Encoder model",
					"keywords": ["driver-action-recognition-adas-0002-encoder","action-recognition-0001-encoder","weld-porosity-detection-0001","i3d-rgb-tf"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "driver-action-recognition-adas-0002-encoder",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_de",
					"devicearguments": "",
					"usage": "decoder model, Only for en-de model, if not, please skip it. ",
					"keywords": ["driver-action-recognition-adas-0002-decoder","action-recognition-0001-decoder"],
					"keywordsType": "name",
					"banlist": [],
					"required": false,
					"directRun": false,
					"default": {
						"name": "driver-action-recognition-adas-0002-decoder",
						"device": "",
						"precision":"FP32"
					}
				}
			],
			"archType":[
				{
					"name": "en-de",
					"models": ["encoder"],
					"argument": "en-de"
				},
				{
					"name": "en-mean",
					"models": ["weld-porosity-detection-0001"],
					"argument": "en-mean"
				},
				{
					"name": "i3d-rgb",
					"models": ["i3d-rgb-tf"],
					"argument": "i3d-rgb"
				}
			],
			"labels":[
				{
					"name": "driver_actions.txt",
					"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/action_recognition_demo/python/driver_actions.txt",
					"applyModels": [],
					"default": true
				}
			]
		},
		{
			"name": "Multi Camera Multi Target Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/multi_camera_multi_target_tracking_demo/python/",
			"fileName": "multi_camera_multi_target_tracking_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify 2 inputs to process. The inputs must be indexes of cameras or paths to vide files. sperate them by space",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Cameras (ID:0 + ID:1)",
					"path": "0 1"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "object detection model",
					"keywords": ["person-detection-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "person-detection-retail-0013",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "--m_segmentation",
					"devicearguments": "-d",
					"usage": "object instance segmentation model",
					"keywords": ["instance-segmentation-security"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "instance-segmentation-security-0228",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "--m_reid",
					"devicearguments": "",
					"usage": "object re-identification model",
					"keywords": ["person-reidentification","vehicle-reid"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "person-reidentification-retail-0277",
						"device": "",
						"precision":"FP32"
					}
				}
			],
			"archType":[
				{
					"name": "Object Detection",
					"argument": "-m"
				},
				{
					"name": "Object Instance Segmentation",
					"argument": "--m_segmentation"
				}
			],
			"labels":[
				{
					"name": "driver_actions.txt",
					"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/action_recognition_demo/python/driver_actions.txt",
					"applyModels": [],
					"default": true
				}
			]
		},
		{
			"name": "Colorization Demo",
			"path": "${INTEL_OPENVINO_DIR}/inference_engine/demos/colorization_demo/python/",
			"fileName": "colorization_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "--loop",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "0"
				},
				{
					"default": true,
					"name": "Mono Picture in 1960s (by henry1758f)",
					"fileName": "1960s_Taiwan_Taichung.jpg",
					"path": "<DOWNLOAD>/1960s_Taiwan_Taichung.jpg",
					"source": "https://synnexopenvinodemo.blob.core.windows.net/synnexopenvinodemo/img1450.jpg"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Colorization Model",
					"keywords": ["colorization"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "colorization-siggraph",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Gesture Recognition Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/gesture_recognition_demo/python/",
			"fileName": "gesture_recognition_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m_a",
					"devicearguments": "-d",
					"usage": "Trained Gesture Recognition Model",
					"keywords": ["asl-recognition"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "asl-recognition-0004",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_d",
					"devicearguments": "",
					"usage": "Trained Person Detection model",
					"keywords": ["person-detection-asl"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "person-detection-asl-0001",
						"device": "",
						"precision":"FP32"
					}
				}
			],
			"labels":[
				{
					"name": "msasl100.json",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/data/dataset_classes/msasl100.json",
					"applyModels": [],
					"default": true
				}
			]
		},
		{
			"name": "Face Recognition Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/face_recognition_demo/python/",
			"fileName": "face_recognition_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "0"
				}
			],
			"models": [
				{
					"argument": "-m_fd",
					"devicearguments": "-d_fd",
					"usage": "Face Detection model",
					"keywords": ["face-detection-adas","face-detection-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "face-detection-retail-0004",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_lm",
					"devicearguments": "-d_lm",
					"usage": "acial Landmarks Detection model",
					"keywords": ["landmarks-regression-retail"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "landmarks-regression-retail-0009",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_reid",
					"devicearguments": "-d_reid",
					"usage": "Face Reidentification model",
					"keywords": ["face-reidentification-retail","Sphereface","facenet","face-recognition-resnet100-arcface-onnx"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "face-reidentification-retail-0095",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			],
			"faceGallery":"/Pictures/face_gallery"
		},
		{
			"name": "Social Distance Demo",
			"path": "$DEMO_LOC/",
			"fileName": "social_distance_demo",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be a single image, a folder of images, video file or camera id",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": false,
					"name": "Camera (ID:0)",
					"path": "/dev/video0"
				},
				{
					"default": true,
					"name": "Sample video about person walking [6.1MB](from GitHub by intel-iot-devkit/sample-videos)",
					"fileName": "face-demographics-walking.mp4",
					"path": "<DOWNLOAD>/face-demographics-walking.mp4",
					"source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/face-demographics-walking.mp4"
				}
			],
			"models": [
				{
					"argument": "-m_det",
					"devicearguments": "-d_det",
					"usage": "Person Detection model",
					"keywords": ["person-detection"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "person-detection-retail-0013",
						"device": "CPU",
						"precision":"FP32"
					}
				},
				{
					"argument": "-m_reid",
					"devicearguments": "-d_reid",
					"usage": "Person Re-Identification model",
					"keywords": ["person-reidentification"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": false,
					"default": {
						"name": "person-reidentification-retail-0277",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Whiteboard Inpainting Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/whiteboard_inpainting_demo/python/",
			"fileName": "whiteboard_inpainting_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be Path to a video file or a device node of a webcam.",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Camera (ID:0)",
					"path": "/dev/video0"
				},
				{
					"default": false,
					"name": "Sample video about person walking [6.1MB](from GitHub by intel-iot-devkit/sample-videos)",
					"fileName": "face-demographics-walking.mp4",
					"path": "<DOWNLOAD>/face-demographics-walking.mp4",
					"source": "https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/face-demographics-walking.mp4"
				}
			],
			"models": [
				{
					"argument": "-m_TODO",
					"devicearguments": "-d",
					"usage": "Instance/Semantic Segmentation model",
					"keywords": ["instance-segmentation","semantic-segmentation-adas"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "instance-segmentation-security-0228",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "MonoDepth Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/monodepth_demo/python/",
			"fileName": "monodepth_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Specify an input to process. The input must be Path to a input image file",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Default Picture",
					"fileName": "car_1.bmp",
					"path": "${INTEL_OPENVINO_DIR}/deployment_tools/demo/car_1.bmp"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "trained model",
					"keywords": ["fcrn-dp-nyu-depth-v2-tf","midasnet"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "midasnet",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		},
		{
			"name": "Text-to-speech Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/text_to_speech_demo/python/",
			"fileName": "text_to_speech_demo.py",
			"InputArguments": "--input",
			"InputHints": " Input the Path for a text file, or Use OpenVINO_Demo_Kit/testing_source/speech_text.txt as default.",
			"addArguments": "",
			"defaultInputs":[
				{
					"default": true,
					"name": "Default Text",
					"fileName": "speech_text.txt",
					"path": "Source/testing_source/"
				}
			],
			"selectionsInfo":"Select Which kind of speech synthesis you want to run.",
			"selections": [
				{
					"name": "Speech synthesis with ForwardTacotron and WaveRNN models",
					"argument":"",
					"models":[
						{
							"argument": "--model_duration",
							"devicearguments": "-d",
							"usage": "",
							"keywords": ["forward-tacotron-duration-prediction"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "forward-tacotron-duration-prediction",
								"device": "CPU",
								"precision":"FP32"
							}
						},
						{
							"argument": "--model_forward",
							"devicearguments": "",
							"usage": "",
							"keywords": ["forward-tacotron-regression"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "forward-tacotron-regression",
								"device": "",
								"precision":"FP32"
							}
						},
						{
							"argument": "--model_upsample",
							"devicearguments": "",
							"usage": "",
							"keywords": ["wavernn-upsampler"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "wavernn-upsampler",
								"device": "",
								"precision":"FP32"
							}
						},
						{
							"argument": "--model_rnn",
							"devicearguments": "",
							"usage": "",
							"keywords": ["wavernn-rnn"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "wavernn-rnn",
								"device": "",
								"precision":"FP32"
							}
						}
					]
				},
				{
					"name": "Speech synthesis with text-to-speech-en-0001 models",
					"argument":"",
					"models":[
						{
							"argument": "-m_duration",
							"devicearguments": "-d",
							"usage": "",
							"keywords": ["text-to-speech-en-0001-duration-prediction"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "text-to-speech-en-0001-duration-prediction",
								"device": "CPU",
								"precision":"FP32"
							}
						},
						{
							"argument": "-m_forward",
							"devicearguments": "",
							"usage": "",
							"keywords": ["text-to-speech-en-0001-regression"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "text-to-speech-en-0001-regression",
								"device": "",
								"precision":"FP32"
							}
						},
						{
							"argument": "-m_melgan",
							"devicearguments": "",
							"usage": "",
							"keywords": ["text-to-speech-en-0001-generation"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "text-to-speech-en-0001-generation",
								"device": "",
								"precision":"FP32"
							}
						}
					]
				},
				{
					"name": "Speech synthesis with multi-speaker text-to-speech-en-multi-0001 models",
					"argument":"-s_id 19",
					"models":[
						{
							"argument": "-m_duration",
							"devicearguments": "-d",
							"usage": "",
							"keywords": ["text-to-speech-en-multi-0001-duration-prediction"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "text-to-speech-en-multi-0001-duration-prediction",
								"device": "CPU",
								"precision":"FP32"
							}
						},
						{
							"argument": "-m_forward",
							"devicearguments": "",
							"usage": "",
							"keywords": ["text-to-speech-en-multi-0001-regression"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "text-to-speech-en-multi-0001-regression",
								"device": "",
								"precision":"FP32"
							}
						},
						{
							"argument": "-m_melgan",
							"devicearguments": "",
							"usage": "",
							"keywords": ["text-to-speech-en-multi-0001-generation"],
							"keywordsType": "name",
							"banlist": [],
							"required": true,
							"directRun": false,
							"default": {
								"name": "text-to-speech-en-multi-0001-generation",
								"device": "",
								"precision":"FP32"
							}
						}
					]
				}
			]
		},
		{
			"name": "Real Time Speech Recognition Demo",
			"path": "${INTEL_OPENVINO_DIR}/deployment_tools/demo/",
			"fileName": "demo_speech_recognition.sh",
			"InputArguments": "",
			"InputHints": "",
			"addArguments": "",
			"defaultInputs":[],
			"models": []
		},
		{
			"name": "BERT Named Entity Recognition Demo",
			"path": "$INTEL_OPENVINO_DIR/inference_engine/demos/bert_named_entity_recognition_demo/python/",
			"fileName": "bert_named_entity_recognition_demo.py",
			"InputArguments": " -i ",
			"InputHints": " Select or input a website as input source. ",
			"addArguments": "",
			"vocab": "public/bert-base-ner/bert-base-ner/vocab.txt",
			"defaultInputs":[
				{
					"default": true,
					"name": "BBC News Website",
					"path": "https://www.bbc.com/news"
				}
			],
			"models": [
				{
					"argument": "-m",
					"devicearguments": "-d",
					"usage": "Named Entity Recognition (NER) model",
					"keywords": ["bert-base-ner"],
					"keywordsType": "name",
					"banlist": [],
					"required": true,
					"directRun": true,
					"default": {
						"name": "bert-base-ner",
						"device": "CPU",
						"precision":"FP32"
					}
				}
			]
		}
	]
}
